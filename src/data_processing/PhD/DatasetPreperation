import gc
import io
import zipfile
from glob import glob
import cv2
import image_slicer
import numpy as np
from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout
from keras.models import Sequential
from keras.optimizers import RMSprop, adam
from keras.utils import np_utils
from keras import models
from keras import regularizers
import tensorflow as tf
import matplotlib.pyplot as plt
from keras_preprocessing.image import ImageDataGenerator

gc.collect()


# reszie and crop images( reszie image to 448*448 and crop the upper right side (224*224),
# and slice the image into 49 tiles

def Resize_Crop_Slice(path):
    global zip
    img_names = glob(path)
    # resizing and cropping
    for fn in img_names:
        images = cv2.imread(fn, 1)
        hight = 448
        width = 448
        dim = (hight, width)
        images = cv2.resize(images, dim)
        images = images[0:224, 224:448]
        cv2.imwrite(fn, images)

    # slicing the image into 49 tiles
    size = range(np.size(img_names))
    sliced_images = []
    zipped = zip(size, img_names)
    for i, fn in zipped:
        print(fn)
        # os.chdir('/home/abdalraheem/Desktop/lions')
        tiles = image_slicer.slice(fn, 49)
        sliced_images.append(tiles)
        with zipfile.ZipFile('tiles.zip' + str(i), 'w') as zip:
            for tile in tiles:
                with io.BytesIO() as data:
                    tile.save(data)
                    zip.writestr(tile.generate_filename(path=None),
                                 data.getvalue())


# Loading images data and labels from their paths
def load_data(path):
    images_mat = []
    for fn in glob(path):
        image = cv2.imread(fn, 0)
        images_mat.append(image)
    loaded_data = np.asarray(images_mat)
    return loaded_data


path1 = 'E:/Project_DataSet/PhD_PROJECT_DATA/data/raw/num/Training_Images/*_output/RMS_flat_shell_Vz_*_500x500top_*_*.png'

path2 = 'E:/Project_DataSet/PhD_PROJECT_DATA/data/raw/num/Training_Labels/m_*_delam*_position_no_*_a_*mm_b_*mm_angle_*_*_*.png'

path3 = 'E:/Project_DataSet/PhD_PROJECT_DATA/data/raw/num/Testing_Images/*_output/RMS_flat_shell_Vz_*_500x500top_*_*.png'

path4 = 'E:/Project_DataSet/PhD_PROJECT_DATA/data/raw/num/Testing_Labels/m_*_delam*_position_no_*_a_*mm_b_*mm_angle_*_*_*.png'

# Resize_Crop_Slice(path1)
# Resize_Crop_Slice(path2)
# Resize_Crop_Slice(path3)
# Resize_Crop_Slice(path4)


Training_image = load_data(path1)
Training_image = Training_image.reshape(18522, 32, 32, 1)
# Normalizing the input data
Training_image = Training_image.astype('float64')
mean = np.mean(Training_image, axis=0)
Training_image -= mean
std =np.std(Training_image,axis=0)
Training_image /= std

print('Training Images shape :', Training_image.shape)
print(Training_image[1].shape)

Testing_Images = load_data(path3)
Testing_Images = Testing_Images.reshape(4655, 32, 32, 1)
Testing_Images = Testing_Images.astype('float64')
Testing_Images -= mean
Testing_Images /= std

print('Testing Images shape :', Testing_Images.shape)

Training_Labels = load_data(path2)
print('Training Labels shape :', Training_Labels.shape)

Testing_Labels = load_data(path4)
print('Testing Labels shape :', Testing_Labels.shape)

Label = []
# Labels must be in one and zero, change label to array of 18522*1 dim instead of 18522*32*32
for i in range(0, Training_Labels.shape[0]):
    Label.append(np.max(Training_Labels[i]))

Training_Labels = np.asarray(Label) / 255
print(list(enumerate(Training_Labels)),'\n')  # TO view Labels in order
print('Training Labels new shape:', Training_Labels.shape)

Label = []
# Labels must be in one and zero, change label to array of 4655*1 dim instead of 4655*32*32
for i in range(Testing_Labels.shape[0]):
    Label.append(np.max(Testing_Labels[i]))

Testing_Labels = np.asarray(Label) / 255
print(list(enumerate(Testing_Labels)), '\n')
print('Testing Labels new shape:', Testing_Labels.shape)

#Training_Labels.reshape(18522,1)
#Testing_Labels.reshape(4655,1)

Training_Labels = np_utils.to_categorical(Training_Labels,2)
Testing_Labels = np_utils.to_categorical(Testing_Labels,2)

# Configuring the model
model = Sequential()
First_convolution_layer = model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 1)))
First_subsambling_Layer = model.add(MaxPool2D((2, 2), strides=2))
Second_convolution_layer = model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
Second_subsambling_Layer = model.add(MaxPool2D((2, 2), strides=2))
Flatting_Layer = model.add(Flatten())
First_Dropout_layer = model.add(Dropout(0.5))
First_FC_layer = model.add(Dense(4096, activation='relu'))
Second_Dropout_layer = model.add(Dropout(0.5))
Second_FC_layer = model.add(Dense(1024, activation='relu'))
Final_output = model.add(Dense(2))

# Compile model using accuracy to measure model performance

model.compile(
    optimizer=adam(lr=0.001),
    loss='mse',
    metrics=['accuracy'])

# Training the model
# validation_data=(Testing_Images, Testing_Labels)
model.fit(Training_image, Training_Labels, batch_size=98, epochs=3)

layers_outputs = [layer.output for layer in model.layers[:9]]

model.summary()

# evaluate the model and print the results
score = model.evaluate(Testing_Images, Testing_Labels, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# model.save_weights("Initial_Model.h5")
# print("Saved model to disk")

p = 94
output =[]
predected_output = model.predict(Testing_Images[49*p:49*(p+1)])
for i in range(49):
    print('0 undamged, 1 dameged :',np.argmax(predected_output[i]))
    output.append(np.argmax(predected_output[i]))


output= np.asarray(output)
output = output.reshape((7,7))
print(output.shape)
print(output)

final =np.zeros((224,224))
for i in range(49):
    for j,k in range(7,7):
        for l,m in range(32,32):
            final[l,m] = output[i]
print(final.shape)



cv2.imshow('image', np.asarray(final))
cv2.waitKey(0)
cv2.destroyAllWindows()
