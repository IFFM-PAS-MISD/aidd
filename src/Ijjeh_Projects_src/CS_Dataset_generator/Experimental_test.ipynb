{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e140f985-b084-4040-9653-14dea99684cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import PIL\n",
    "from PIL import ImageOps\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from tensorflow.python.client import device_lib\n",
    "import random\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import cv2\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d3530-7f06-443a-8479-7cc65dc5c4cd",
   "metadata": {},
   "source": [
    "# Selecting GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06321c94-fcad-4257-b661-a58b9c20a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19375b7-607d-49fb-8825-b6e28c934eb4",
   "metadata": {},
   "source": [
    "# Loading the model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a83018-d4d5-4f0a-ad39-96c137f7a42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/aijjeh/Desktop/Phd_Projects/Sequence_prediction/Sequence_to_sequence/h5_models/')\n",
    "model_name = \"UNet_Xception_style_model_24.h5\" \n",
    "model = load_model(model_name, compile=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c755c59-aab5-4859-a784-bcc9db75a831",
   "metadata": {},
   "source": [
    "# Write the name of the experimental case here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fccee-8246-4a3f-90de-b77c6dcb1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'L3_S4_B'\n",
    "exp_case = '333x333p_50kHz_10HC_18Vpp_x10_pzt'\n",
    "exp_gt = 'label_'+ exp_name + '_' +  exp_case + '.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6556f9f-d9c1-4a7b-9037-d3938dd39f9f",
   "metadata": {},
   "source": [
    "# Testing directories and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74486845-27e8-4666-982b-cbff9c15499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/aijjeh_odroid_sensors/aidd/data/interim/exp/\" + exp_name + '/' + exp_case # \n",
    "# input_dir = \"/home/aijjeh/Desktop/Phd_Projects/compressive_sensing_project/Experimental/Uniform_mesh_2nd_model/Upated_version/\"\n",
    "target_dir = \"/aijjeh_odroid_sensors/aidd/data/interim/exp/new_exp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e29eee-74b4-4857-889f-60a788c1a45c",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a2a7a-b1c0-4b49-98dc-10f47fb7c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "height =  512 #500 # \n",
    "width = 512 #  500 # \n",
    "img_size = (height, width)\n",
    "num_classes = 2\n",
    "batch_size = 1\n",
    "time_stamps = 24 # 64\n",
    "input_img_paths_total = [None]*1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6756fc3-acc9-4fb0-b840-58a0fa1521e3",
   "metadata": {},
   "source": [
    "# Function to convet atoi and sorting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b8f17-891f-46df-b0f5-9da803e99086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54fe4b9-6e6e-4a3a-8e73-33dafc5af985",
   "metadata": {},
   "source": [
    "# Load cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf6804f-7fb8-4025-a866-a8e426e6827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv = '/home/aijjeh/aijjeh_rexio_share/PhD/cmap_flipped_jet256.csv'\n",
    "cmap = matplotlib.colors.ListedColormap([\"blue\", \"green\", \"red\"], name=path_to_csv, N=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fed776e-c8b0-46f9-8e27-931b8769c841",
   "metadata": {},
   "source": [
    "# Getting paths of the experimental test data (Full wavefield frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b96246-11d2-41f9-a5b8-a4b3023f552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = os.listdir(input_dir)\n",
    "my_list.sort(key=natural_keys)\n",
    "print(len(my_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb16d8-2521-47e8-96e4-c146554b3fa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname) \n",
    "        for fname in os.listdir(input_dir)    \n",
    "        if fname.endswith(\".png\")\n",
    "    ])\n",
    "input_img_paths.sort(key=natural_keys)\n",
    "input_img_paths_total[0]= input_img_paths\n",
    "print((input_img_paths_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca262d-213c-4ea0-92a6-6ee6a6ac433c",
   "metadata": {},
   "source": [
    "# Getting the ground truth image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee1cda-1c52-4844-832b-a244962518ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith(exp_gt) and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "target_img_paths.sort(key=natural_keys)\n",
    "print((target_img_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3b694-3e1a-4c4c-8bc7-5533a85ae532",
   "metadata": {},
   "source": [
    "# Defining the calling funtion for loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb936d11-267b-4169-85ed-48d7d996e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Full_wavefield_frames(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, img_size, input_img_paths_total_, target_img_paths_, time_stamps, frame_init):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths_total = input_img_paths_total_\n",
    "        self.target_img_paths = target_img_paths_\n",
    "        self.time_stamps = time_stamps\n",
    "        self.frame_num = frame_init\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size        \n",
    "        batch_input_img_paths = self.input_img_paths_total[i:i+self.batch_size]      \n",
    "        batch_target_img_paths = self.target_img_paths[i:i+self.batch_size] \n",
    "        \n",
    "        x = np.zeros((self.batch_size,) + (self.time_stamps,) + self.img_size + (1,), dtype=\"float32\") #  \n",
    "        \n",
    "        for batch_num in range(self.batch_size):\n",
    "            batch_input_img_paths = batch_input_img_paths[batch_num][self.frame_num:self.frame_num+self.time_stamps] \n",
    "            for j, path in enumerate(batch_input_img_paths):\n",
    "                img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")            \n",
    "                img = np.expand_dims(img,2)\n",
    "                img = img / 255.0\n",
    "                x[batch_num][j] = img\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")            \n",
    "            img = np.expand_dims(img, 2)\n",
    "            img = img / 255.0\n",
    "            y[j] = img\n",
    "                # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
    "                # y[j] -= 1\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a009c0-01a4-4069-b037-825267bb965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_img_paths = input_img_paths_total[:]\n",
    "test_target_img_paths = target_img_paths[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ef9494-3827-408a-a142-5e6481986823",
   "metadata": {},
   "source": [
    "# csv file to append results of iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932300c-7954-48ad-a578-bbed315c59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_file_name = exp_name + '_' + exp_case +'_Ijjeh_SR_.csv' # exp_name + \n",
    "def append_list_as_row(cvs_file_name, list_of_iou, image_num):\n",
    "    os.chdir('/home/aijjeh/Desktop/Phd_Projects/Sequence_prediction/Full_wavefield_frames_time_series_project/AE_exp_results_frames_24_512_512')\n",
    "    with open(cvs_file_name, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([image_num])\n",
    "        writer.writerows([list_of_iou])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280489ff-7560-4ec6-9dab-058968392a31",
   "metadata": {},
   "source": [
    "# Calculating IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5413a46-bc6b-468d-a0e7-5640102612e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_IoU(predicted_image, truth_img, frame):\n",
    "    predicted_image = np.asarray(predicted_image) # \n",
    "    predicted_image = predicted_image.astype('float64')\n",
    "    ret, predicted_image = cv2.threshold(predicted_image, .5, 1.0, cv2.THRESH_BINARY)\n",
    "    truth_img = np.asarray(truth_img)# \n",
    "    truth_img = truth_img.astype('float64')\n",
    "    ret_, truth_img = cv2.threshold(truth_img, .5, 1.0, cv2.THRESH_BINARY)\n",
    "\n",
    "    truth_img = truth_img[:,:,0]\n",
    "    InterSectionArray = cv2.bitwise_and(predicted_image, truth_img)\n",
    "    UnionArray = cv2.bitwise_or(predicted_image, truth_img)\n",
    "    I1 = np.count_nonzero(InterSectionArray)\n",
    "    U = np.count_nonzero(UnionArray)\n",
    "    IoU = I1 / U\n",
    "    print('frame_%d_iou : ' % frame,IoU)\n",
    "    return IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd1212-c6b4-48b0-8d45-3c78cf1728ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_IoU  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea2c1df-0bd7-451c-a06d-e3fbb403f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = '/home/aijjeh/Desktop/Phd_Projects/Sequence_prediction/Full_wavefield_frames_time_series_project/AE_exp_results_frames_24_512_512/'\n",
    "os.chdir(exp_path)\n",
    "exp_dir = exp_path+exp_name+'_Ijjeh_SR_'+exp_case\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.mkdir(exp_dir)\n",
    "os.chdir(exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538220f4-c2c3-457c-a2c1-3cf238cc646d",
   "metadata": {},
   "source": [
    "# Visulaization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1049e-7d98-4aa2-9f38-07465ff88147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res(img, ext, frame):\n",
    "    ############################################################################################################\n",
    "    plt.figure(figsize=(1, 1), dpi=512)\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(left=0.0, bottom=0.0, right=1, top=1.0, wspace=0.0, hspace=0.0)\n",
    "    plt.margins(0, 0)\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    ############################################################################################################\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.savefig(exp_name + '_' + exp_case + '_' + ext + '_%d' % frame)\n",
    "    # plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab0e753-2e04-41c9-ae96-fcfa228440f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_frames = []\n",
    "list_iou = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d950ab-ea93-4496-ad3c-8f06d9f263ab",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for frame_init in range(0, len(my_list)-24):\n",
    "    val_gen = Full_wavefield_frames(batch_size, img_size, input_img_paths_total, target_img_paths, time_stamps, frame_init)\n",
    "    val_preds = model.predict(val_gen)\n",
    "    \n",
    "    # Display input image\n",
    "    \n",
    "    img_input_ = val_gen[0][0][0]\n",
    "    img_input_ = (img_input_[23]*255).astype(np.uint8)\n",
    "    # plot_res(img_input_, 'Last_input_frame')\n",
    "\n",
    "    # Display ground-truth target mask\n",
    "    \n",
    "    img_GT_ = PIL.ImageOps.autocontrast(load_img(test_target_img_paths[0], target_size= img_size))\n",
    "    # plot_res(img_GT_, 'Ground_truth', frame_init)\n",
    "    \n",
    "    # Display mask predicted by our model\n",
    "    \n",
    "    mask = val_preds[0]\n",
    "    img_pred_ = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
    "    plot_res(img_pred_, 'predicted_output', frame_init)\n",
    "    iou = calc_IoU(mask, img_GT_, frame_init)       \n",
    "    total_IoU = total_IoU + iou\n",
    "    list_frames.append(frame_init)\n",
    "    list_iou.append(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67e3d5-7c4f-47b4-b2a7-237f8b229d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_list_as_row(cvs_file_name, list_iou, list_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261a18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
