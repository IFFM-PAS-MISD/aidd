{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c33afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "__title__ = 'Modelling guided waves'\n",
    "__author__ = \"Abdalraheem A. Ijjeh\"\n",
    "__maintainer__ = \"Abdalraheem A. Ijjeh\"\n",
    "__email__ = \"aijjeh@imp.gda.pl\"\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07321db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import neptune.new as neptune\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import re\n",
    "import neptune.new as neptune\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from PIL import ImageOps\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score,  mean_squared_error\n",
    "from decouple import config\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6634939",
   "metadata": {},
   "source": [
    "# Link to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07207987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access_token = os.getenv('NEPTUNE_API_TOKEN')\n",
    "# run = neptune.init_run(project='abdalraheem.ijjeh/Guided-waves-modelling',\n",
    "#                        api_token=access_token,\n",
    "#                        tags=['DL HR_FFT2D_guided_waves_modelling', 'Fourier_domain']\n",
    "#                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92025c70",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ccd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run[\"Signal_based\"] = \"AE\"\n",
    "params = {'batches': 1,\n",
    "          'num_filters': 24,\n",
    "          'kernel_size': 3,\n",
    "          'shape': (32, 32),\n",
    "          'epochs': 10000,\n",
    "          'dropout': 0.2,\n",
    "          'levels': 4,\n",
    "          'learning_rate': 0.00014329,\n",
    "          'patience_epochs': 100,\n",
    "          'val_split': 0.08,\n",
    "          'hidden_layer': 3,\n",
    "          'decay:steps': 100000,\n",
    "          'decay_rate': 0.96,\n",
    "          'time_stamps': 32\n",
    "          }\n",
    "\n",
    "# run[\"model/parameters\"] = params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99536f0a",
   "metadata": {},
   "source": [
    "# Run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "# \n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# for device in physical_devices:\n",
    "#     tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a42db78",
   "metadata": {},
   "source": [
    "# Save the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0825a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_path = '/home/aijjeh/Desktop/Phd_Projects/Modeling_guided_waves/'\n",
    "# os.chdir(env_path)\n",
    "# json = json.dumps(params)\n",
    "# f = open('hyper_par_GWM_mse.json', 'w')\n",
    "# f.write(json)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd794fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e16fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/aijjeh_odroid_sensors/aidd/data/raw/num/wavefield_dataset_undelam_bottom_out/1_output\"\n",
    "target_dir_ = \"/aijjeh_odroid_sensors/aidd/data/raw/num/wavefield_dataset2_bottom_out\"\n",
    "my_list = os.listdir(input_dir)\n",
    "my_list.sort(key=natural_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efbe72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_paths_total = []\n",
    "target_img_paths_total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f442e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(475):\n",
    "    input_img_paths = sorted( \n",
    "        [\n",
    "            os.path.join(input_dir, fname) \n",
    "            for fname in os.listdir(input_dir)    \n",
    "            if fname.endswith(\".png\")\n",
    "        ] \n",
    "    )\n",
    "    input_img_paths.sort(key=natural_keys)\n",
    "    input_img_paths_total.append(input_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b61dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(input_img_paths_total[0][80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(input_img_paths_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de794f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(475):\n",
    "    target_dir = target_dir_ +'/%d_output' % (i+1) #str(my_list[i])\n",
    "    target_img_paths = sorted( \n",
    "        [\n",
    "            os.path.join(target_dir, fname) \n",
    "            for fname in os.listdir(target_dir)    \n",
    "            if fname.endswith(\".png\")\n",
    "        ] \n",
    "    )\n",
    "    target_img_paths.sort(key=natural_keys)\n",
    "    target_img_paths_total.append(target_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(target_img_paths_total[0][80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(target_img_paths_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdefcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/aijjeh/Desktop/Phd_Projects/Sequence_prediction/Full_wavefield_frames_time_series_project/Datasets/label_set')\n",
    "file_frame = np.load('frames_initial.npy')\n",
    "file_frame = file_frame[:380]\n",
    "print(file_frame[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/aijjeh/Desktop/Phd_Projects/Modeling_guided_waves/dataset')\n",
    "X_train_1 = np.load('LR_GT_del.npy')\n",
    "arr = X_train_1.reshape((475, 1, 5))\n",
    "arr = np.repeat(arr, 32, axis=1)\n",
    "print(arr.shape)\n",
    "arr = arr.reshape((475, 32,1,5))\n",
    "arr = np.repeat(arr, 32, axis=2)\n",
    "print(arr.shape)\n",
    "arr = arr.reshape((475,1,32,32,5))\n",
    "arr = np.repeat(arr, 32, axis=1)\n",
    "\n",
    "print(arr.shape)\n",
    "arr = arr[:380]\n",
    "\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea2b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Full_wavefield_frames(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_size,\n",
    "                 img_size, input_imgs_paths_total,\n",
    "                 target_imgs_paths_total,\n",
    "                 input_coords,\n",
    "                 time_stamps):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths_total = input_imgs_paths_total\n",
    "        self.target_img_paths = target_imgs_paths_total\n",
    "        self.input_coord = input_coords\n",
    "        self.time_stamps = time_stamps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_img_paths_total) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        z = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths_total[z:z + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[z:z + self.batch_size]\n",
    "        batch_input_coords = self.input_coord[z:z + self.batch_size]\n",
    "\n",
    "        x1 = np.zeros((self.batch_size,) + (self.time_stamps,) + self.img_size + (1,), dtype=\"float16\")  #\n",
    "        x2 = np.zeros((self.batch_size,) + (self.time_stamps,) + self.img_size + (5,), dtype=\"float16\")  #\n",
    "\n",
    "        x_in = np.zeros((self.batch_size,) + (self.time_stamps,) + self.img_size + (6,), dtype=\"float16\")  #\n",
    "\n",
    "        for batch_num in range(self.batch_size):\n",
    "            batch_input_img_paths = batch_input_img_paths[batch_num][file_frame[z] - 8: file_frame[z] + 24]\n",
    "            batch_input_coords = batch_input_coords[batch_num][:]  # file_frame[z] - 8: file_frame[z] + 8\n",
    "            count = 0\n",
    "            for j, path in enumerate(batch_input_img_paths):\n",
    "                img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "                img = np.expand_dims(img, 2)\n",
    "                img = img / 255.0\n",
    "\n",
    "                x1[batch_num][j] = img\n",
    "\n",
    "                coords = arr[batch_num][count]\n",
    "                x2[batch_num][j] = coords\n",
    "                count += 1\n",
    "            x_in = np.concatenate([x1, x2], axis=-1)\n",
    "\n",
    "        y = np.zeros((self.batch_size,) + (self.time_stamps,) + self.img_size + (1,), dtype=\"float16\")  #\n",
    "\n",
    "        for batch_num in range(self.batch_size):\n",
    "            batch_target_img_paths = batch_target_img_paths[batch_num][file_frame[z] - 8:file_frame[z] + 24]\n",
    "            for j, path in enumerate(batch_target_img_paths):\n",
    "                img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "                img = np.expand_dims(img, 2)\n",
    "                img = img / 255.0\n",
    "                y[batch_num][j] = img\n",
    "\n",
    "        return x_in, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183643fc",
   "metadata": {},
   "source": [
    "# Split our img paths into a training and a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b4ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_input_img_paths = input_img_paths_total[:304]\n",
    "# print(len(train_input_img_paths))\n",
    "train_target_img_paths = target_img_paths_total[:304]\n",
    "# print(len(train_target_img_paths))\n",
    "val_input_img_paths = input_img_paths_total[304:380]\n",
    "# print(len(val_input_img_paths))\n",
    "val_target_img_paths = target_img_paths_total[304:380]\n",
    "\n",
    "\n",
    "# Instantiate data Sequences for each split\n",
    "train_gen = Full_wavefield_frames(params['batches'],\n",
    "                                  params['shape'],\n",
    "                                  train_input_img_paths, \n",
    "                                  train_target_img_paths,\n",
    "                                  arr[:304],\n",
    "                                  params['time_stamps']) \n",
    "\n",
    "val_gen = Full_wavefield_frames(params['batches'],\n",
    "                                params['shape'], \n",
    "                                val_input_img_paths, \n",
    "                                val_target_img_paths,\n",
    "                                arr[304:],\n",
    "                                params['time_stamps'])\n",
    "print('0 axis',len(train_gen[0]))\n",
    "print('1 axis',len(train_gen[0][0]))\n",
    "print('2 axis',len(train_gen[0][0][0]))\n",
    "print('3 axis',len(train_gen[0][0][0][0]))\n",
    "print('4 axis',len(train_gen[0][0][0][0][0]))\n",
    "print('5 axis',len(train_gen[0][0][0][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f2974",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c0d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(304):\n",
    "    x.append(train_gen[i][0])\n",
    "    y.append(train_gen[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_distributed(time_input, n_filters):\n",
    "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(filters=n_filters,\n",
    "                               kernel_size=params['kernel_size'],\n",
    "                               strides=1, \n",
    "                               padding='same',\n",
    "                               activation='relu'))(time_input)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ea4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_batch(bn_input):\n",
    "    return tf.keras.layers.BatchNormalization()(bn_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23118d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_FFT2D(y_true, y_pred):\n",
    "    y_true_k = y_true\n",
    "    y_pred_k = y_pred\n",
    "    \n",
    "    fft2d_true = tf.transpose(y_pred_k,[])\n",
    "    fft2d_true = tf.signal.fft(tf.cast(y_true_k, dtype=tf.complex64))\n",
    "    fft2d_pred = tf.signal.fft(tf.cast(y_pred_k, dtype=tf.complex64))\n",
    "    \n",
    "    N = tf.size(fft2d_true)\n",
    "    N = tf.cast(N, dtype=tf.float32)\n",
    "\n",
    "    fft2d_true = tf.signal.fftshift(fft2d_true, axes=(-1))\n",
    "    fft2d_pred = tf.signal.fftshift(fft2d_pred, axes=(-1))\n",
    "\n",
    "    fft2d_true = tf.cast(fft2d_true, dtype=tf.float32)\n",
    "    fft2d_pred = tf.cast(fft2d_pred, dtype=tf.float32)\n",
    "\n",
    "    fft2d_pred = tf.divide(fft2d_pred, N)\n",
    "    fft2d_true = tf.divide(fft2d_true, N)\n",
    "\n",
    "    MSE_Fourier_domain = tf.losses.MSE(abs(fft2d_true), abs(fft2d_pred))\n",
    "    MSE_Spatial = tf.losses.MSE(y_true, y_pred)\n",
    "\n",
    "    return MSE_Fourier_domain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    params['learning_rate'],\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da017557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=((params['time_stamps'],)+ (params['shape']) + (6,)))   \n",
    "    print(inputs.shape)\n",
    "    ####################################################################################################################\n",
    "    encoder = get_time_distributed(inputs, params['num_filters'])\n",
    "   \n",
    "    skip_tensor = []\n",
    "    for i in range(params['levels']):\n",
    "        encoder = get_time_distributed(encoder, params['num_filters'])  \n",
    "        encoder = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPool2D((2, 2), strides=(2, 2)))(encoder)\n",
    "        skip_tensor.append(encoder)\n",
    "    print(encoder)\n",
    "    ####################################################################################################################\n",
    "    \n",
    "    bottleneck = get_time_distributed(encoder, params['num_filters']*5)\n",
    "    bottleneck = normalize_batch(bottleneck)\n",
    "    bottleneck = get_time_distributed(bottleneck, params['num_filters']*5)\n",
    "    bottleneck = normalize_batch(bottleneck)\n",
    "    \n",
    "    decoder = bottleneck\n",
    "   # ####################################################################################################################\n",
    "    \n",
    "    for j in (range(1, params['levels'] + 1)):\n",
    "        decoder = tf.keras.layers.concatenate((decoder, skip_tensor[-j]))\n",
    "        decoder = tf.keras.layers.TimeDistributed(tf.keras.layers.UpSampling2D((2, 2)))(decoder)        \n",
    "        decoder = get_time_distributed(decoder, params['num_filters'])\n",
    "            \n",
    "    ####################################################################################################################\n",
    "    lstm_layer = tf.keras.layers.ConvLSTM2D(24, (1, 1), padding='same', return_sequences=True)(decoder)\n",
    "    ####################################################################################################################\n",
    "    # Output layer\n",
    "   \n",
    "    #################################################################################################################### \n",
    "    model_ = Model(inputs=inputs, outputs=lstm_layer)\n",
    "    ####################################################################################################################\n",
    "    model_.compile(tf.keras.optimizers.Adam(lr_schedule),\n",
    "                  loss='mse',\n",
    "                  metrics=[tf.keras.metrics.CosineSimilarity()],\n",
    "                  run_eagerly=False)\n",
    "    return model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# Build model\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = env_path + 'temp/checkpoint/HR_frame_modelling_%s_%d_lr_filters_%d_levels_%d_batches_%d_epochs_%d_dropout_%s_val_split_%s_hidden_%d.h5' % (\n",
    "    params['samples'],\n",
    "    params['learning_rate'],\n",
    "    params['num_filters'],\n",
    "    params['levels'],\n",
    "    params['batches'],\n",
    "    params['epochs'],\n",
    "    params['dropout'],\n",
    "    params['val_split'],\n",
    "    params['hidden_layer'])\n",
    "\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                              patience=params['patience_epochs'],\n",
    "                                              mode='min'),\n",
    "             tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                monitor='val_loss',\n",
    "                                                save_best_only=True)]\n",
    "\n",
    "\n",
    "class MonitoringCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        for metric_name, metric_value in logs.items():\n",
    "            run[metric_name].log(metric_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9be1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_gen,\n",
    "          batch_size=params['batches'],\n",
    "          validation_data=val_gen,\n",
    "          epochs=params['epochs'],\n",
    "          callbacks=[callbacks, MonitoringCallback()]) # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355af3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032090b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1944f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ef9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
