%% SECTION HEADER ////////////////////////////////////////////////////////////////////////////////
\section{Delamination detection using fully connected CNN classifier}
\label{sec42}

In this section, I present my initial attempt to solve the problem of delamination detection in CFRP materials was on utilising CNN models for classification purposes.

The developed models were trained on the on RMS images from the synthetically generated dataset of the propagating Lamb waves (from the top of the surface of the plate) to predict the delamination location using bounding boxes as shown in Fig~\ref{fig:RMS_14}, while, Fig.~\ref{fig:label_14} shows its corresponding ground truth.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure} [h!]
	\centering
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/RMS_flat_shell_Vz_389_500x500top.png}
		\caption{}
		\label{fig:RMS_14}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/m1_rand_single_delam_389.png}
		\caption{}
		\label{fig:label_14}
	\end{subfigure}
	\caption{(a) RMS image: from the top of the plate, (b) Label}
	\label{fig:RMS_GT}
\end{figure} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Accordingly, CNN models with fully connected dense layers were developed for delamination detection in CFRP.
Moreover, the developed models are based on supervised learning to perform a classification task, therefore for each generated case of delamination a ground truth (label) is given.
 
\subsection{Data preprocessing}
\label{sec421}
In order to reduce the computation complexity for the model, the dataset for training the model was prepared by resizing the RMS input image to \((448\times 448)\) pixels.  
Then, it was split it into \((14\times 14)\) blocks, and each block has a size of \((32\times 32)\) pixels as shown in Fig.~\ref{fig:RMS_49blocks}.
Consequently, the preprocessed dataset has a size of \((93100\times 32\times 32 \times 1)\), where (\(93100\)) is the total number of blocks for all \(475\) cases.

To investigate the effect of increasing the resolution of RMS images over delamination identification, I made another preparation by upsampling the RMS input image to \((512\times 512)\) pixels with cubic interpolation. Then the upsampled RMS image was split into \(16\times 16\) blocks, and each block has a size of \((32\times 32)\) pixels as shown in Fig.~\ref{fig:RMS_64blocks}.
The second preprocess dataset has a size of \((121600 \times 32 \times 32 \times 1)\), where (\(121600\)) is the total number of blocks for all \(475\) cases.
For each block in the RMS input image, there is a corresponding block in the ground truth image of size \((32\times 32)\) as presented in Figs.~\ref{fig:GT_49blocks} and~\ref{fig:GT_64blocks}, respectively.

For training purposes, the dataset was divided into two portions: \(80\%\)	training set and \(20\%\) testing set. 
Additionally, the validation set was created as a \(20\%\) of the training set.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure} [h!]
	\centering
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/7_7_blocks_389.png}
		\caption{RMS image splitted into (\(14\times 14\)) blocks.}
		\label{fig:RMS_49blocks}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/8_8_blocks_389.png}
		\caption{RMS image splitted into (\(16\times 16\)) blocks.}
		\label{fig:RMS_64blocks}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/GT_7_7_389.png}
		\caption{Label image splitted into (\(14\times 14\)) blocks.}
		\label{fig:GT_49blocks}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/GT_8_8_389.png}
		\caption{Label image splitted into (\(16\times 16\)) blocks.}
		\label{fig:GT_64blocks}
	\end{subfigure}
	\caption{}
	\label{fig:grid_mesh}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{CNN classification models}
\label{sec422}
The architecture of the implemented CNN model for classification purposes is presented in Fig.~\ref{CNN_model}
The model takes an input block of size \((32\times 32)\) pixels, followed by a convolutional layer that has (\(64\)) filters of size (\(3\times 3\)).
Moreover, in the convolution operation, the padding was set to be the same,  and the activation function was Relu.
Then, a pooling layer is applied, which has a pool filter of size (\(2\times 2\)) with a stride of (\(2\)).
This operation of convolution and pooling is repeated two times.
The output of the second pooling layer is flattened and fed into the dense layers in which the model has two fully connected layers.
The first dense layer has (\(4096\)) neurons, and the second dense layer has (\(1024\)) neurons.
A dropout of probability (\(p = 0.5\)) was added to the model to reduce the overfitting issue.

Moreover, selecting a proper objective function (loss) during training is important as the loss function reflects how well the model learns to predict.
Hence, I have applied the mean square error \((MSE)\) loss function depicted in Eqn.~\ref{mse}, which calculates the sum of the squared distances between the predicted output values and the ground truth values.
\begin{equation}
	MSE=\frac{1}{M*N}\sum_{M,N}^{}(Y_{(m,n)}-\hat{Y}_{(m,n)})^2
	\label{mse}
\end{equation}
where \(M\) and \(N\)) are the number of rows and columns in the input images, \(Y_{(m,n)}\) is the ground truth value, and \(\hat{Y}_{(m,n)}\) is the predicted value.

The final layer in the model is the output layer, in which the model outputs two predictions (damaged and undamaged), hence, softmax activation function was used.
The softmax estimates the probability of each predicted output as being damaged or undamaged, which implies that the sum of the two probabilities must be one.
The softmax activation function is depicted by Eq.~(\ref{softmax}), where \(P(x)_{i}\) is the probability of each target class \(x_{j}\) across all potential target classes \(x_{j}\), C in our instance being two classes (damaged and undamaged).
\begin{equation}
	P(x)_{i} = \frac{e^{x_{i}}}{\sum_{j}^{C} e^{x_{j}}}
	\label{softmax}
\end{equation} 

Additionally, an argmax function is used to find the maximum probability between each of them in order to predict the label of the output (\(y_{pred}\)).
Equation~\ref{argmax} depicts the argmax function.
\begin{equation}
	y_{pred} = argmax_{i}\left( P(x)_{i} \right)
	\label{argmax}
\end{equation}

Accordingly, the whole block of size \((32\times 32)\) is classified as damaged if there is at least one pixel of delamination, otherwise, it is considered undamaged.
Finally, the predicted output (delamination) is surrounded by a bounding box as the final output.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h!]
	\centering
	\includegraphics[scale=1]{Figures/Chapter_4/CNN_model.png}
	\caption{CNN classifier architecture.}
	\label{CNN_model}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
