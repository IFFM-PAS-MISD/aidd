%% SECTION HEADER ////////////////////////////////////////////////////////////////////////////////
\section{Delamination detection using fully connected CNN classifier}
\label{sec42}

In this section, I present my initial attempt to solve the problem of delamination detection in CFRP materials by utilising CNN models for classification purposes.

The bounding box method was used for the classification of the location of the delamination with the input as RMS (Fig.~\ref{fig:RMS_14}) and the binary representation of the delamination shape as ground truth (label shown in Fig.~\ref{fig:label_14}).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure} [!ht]
	\centering
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/RMS_flat_shell_Vz_389_500x500top.png}
		\caption{}
		\label{fig:RMS_14}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/m1_rand_single_delam_389.png}
		\caption{}
		\label{fig:label_14}
	\end{subfigure}
	\caption{(a) RMS image: from the top of the plate, (b) Label.}
	\label{fig:RMS_GT}
\end{figure} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Accordingly, CNN models with fully connected dense layers were developed for delamination detection in CFRP.
Moreover, the developed models are based on supervised learning to perform a classification task, therefore for each generated case of delamination a ground truth (label) is given.
 
\subsection{Data preprocessing}
\label{sec421}
In order to reduce the computation complexity for the model, the dataset for training the model was prepared by resizing the RMS input image to \((448\times 448)\) pixels.  
Then, it was split into \((14\times 14)\) patches, and each patch has a size of \((32\times 32)\) pixels as shown in Fig.~\ref{fig:RMS_49patches}.
Consequently, the preprocessed dataset has a size of \((93100\times 32\times 32 \times 1)\), where (\(93100\)) is the total number of patches for all \(475\) cases.

To investigate the effect of increasing the resolution of RMS images over delamination identification, I made another preparation by upsampling the RMS input image to \((512\times 512)\) pixels with cubic interpolation. Then the upsampled RMS image was split into \(16\times 16\) patches, and each patch has a size of \((32\times 32)\) pixels as shown in Fig.~\ref{fig:RMS_64patches}.
The second preprocess dataset has a size of \((121600 \times 32 \times 32 \times 1)\), where (\(121600\)) is the total number of patches for all \(475\) cases.
For each patch in the RMS input image, there is a corresponding patch in the ground truth image of size \((32\times 32)\) as presented in Figs.~\ref{fig:GT_49patches} and~\ref{fig:GT_64patches}, respectively.

For training purposes, the dataset was divided into two portions: \(80\%\)	training set and \(20\%\) testing set. 
Additionally, the validation set was created as a \(20\%\) of the training set.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure} [h!]
	\centering
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/7_7_patches_389.png}
		\caption{RMS image splitted into (\(14\times 14\)) patches.}
		\label{fig:RMS_49patches}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/8_8_patches_389.png}
		\caption{RMS image splitted into (\(16\times 16\)) patches.}
		\label{fig:RMS_64patches}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/GT_7_7_389.png}
		\caption{Label image splitted into (\(14\times 14\)) patches.}
		\label{fig:GT_49patches}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.47\textwidth}
		\centering
		\includegraphics[width=5cm]{Figures/Chapter_4/GT_8_8_389.png}
		\caption{Label image splitted into (\(16\times 16\)) patches.}
		\label{fig:GT_64patches}
	\end{subfigure}
	\caption{Data preparation for bounding box method.}
	\label{fig:grid_mesh}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{CNN classification models}
\label{sec422}
The architecture of the implemented CNN model for classification purposes is presented in Fig.~\ref{CNN_model}.
The model takes an input patch of size \((32\times 32)\) pixels, followed by a convolutional layer that has (\(64\)) filters of size (\(3\times 3\)).
Moreover, in the convolution operation, the padding was set to be the same,  and the activation function was Relu.
Then, a pooling layer is applied, which has a pool filter of size (\(2\times 2\)) with a stride of (\(2\)).
This operation of convolution and pooling is repeated two times.
The output of the second pooling layer is flattened and fed into the dense layers in which the model has two fully connected layers.
The first dense layer has (\(4096\)) neurons, and the second dense layer has (\(1024\)) neurons.
A dropout of probability (\(p = 0.5\)) was added to the model to reduce the overfitting issue.

Moreover, selecting a proper objective function (loss) during training is important as the loss function reflects how well the model learns to predict.
Hence, I have applied the mean square error \((MSE)\) loss function depicted in Eqn.~\ref{mse}, which calculates the sum of the squared distances between the predicted output values and the ground truth values:
\begin{equation}
	MSE=\frac{1}{M*N}\sum_{M,N}^{}(Y_{(m,n)}-\hat{Y}_{(m,n)})^2,
	\label{mse}
\end{equation}
where \(M\) and \(N\) are the number of rows and columns in the input images, \(Y_{(m,n)}\) is the ground truth value, and \(\hat{Y}_{(m,n)}\) is the predicted value.

The final layer in the model is the output layer, in which the model outputs two predictions (damaged and undamaged).
Hence, the softmax activation function was used, which estimates the probability of each predicted output as being damaged or undamaged, implying that the sum of the two probabilities must be one.
The reason behind choosing the softmax at the output layer is to avoid thresholding of the predicted output (e.g. a sigmoid produces values in a range between (\(0\) and \(1\))).
The softmax activation function is depicted by Eq.~(\ref{softmax}): 
\begin{equation}
	P(x)_{i} = \frac{e^{x_{i}}}{\sum_{j}^{C} e^{x_{j}}}.
	\label{softmax}
\end{equation} 
where \(P(x)_{i}\) is the probability of each target class \(x_{j}\) across all potential target classes \(x_{j}\), C in our instance being two classes (damaged and undamaged).

Additionally, an argmax function is used to find the maximum probability between each of them in order to predict the label of the output (\(y_{pred}\)).
Equation~\ref{argmax} depicts the argmax function.
\begin{equation}
	y_{pred} = \mathrm{argmax}_{i}\left( P(x)_{i} \right)
	\label{argmax}
\end{equation}

Accordingly, the whole patch of size \((32\times 32)\) is classified as damaged if there is at least one pixel of delamination, otherwise, it is considered undamaged.
Finally, the predicted output (delamination) is surrounded by a bounding box as the final output.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h!]
	\centering
	\includegraphics[scale=1]{Figures/Chapter_4/CNN_model.png}
	\caption{CNN classifier architecture.}
	\label{CNN_model}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
