@article{Badrinarayanan2017a,
abstract = {We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network [1]. The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN [2] and also with the well known DeepLab-LargeFOV [3] , DeconvNet [4] architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures and can be trained end-to-end using stochastic gradient descent. We also performed a controlled benchmark of SegNet and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. These quantitative assessments show that SegNet provides good performance with competitive inference time and most efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.},
archivePrefix = {arXiv},
arxivId = {1511.00561},
author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
doi = {10.1109/TPAMI.2016.2644615},
eprint = {1511.00561},
file = {:C$\backslash$:/Users/Saeed Ullah/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Badrinarayanan, Kendall, Cipolla - 2017 - SegNet A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Deep convolutional neural networks,decoder,encoder,indoor scenes,pooling,road scenes,semantic pixel-wise segmentation,upsampling},
month = {dec},
number = {12},
pages = {2481--2495},
pmid = {28060704},
title = {{SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation}},
url = {https://ieeexplore.ieee.org/document/7803544/},
volume = {39},
year = {2017}
}
@article{Sirazitdinov2019a,
abstract = {Pneumonia is a bacterial, viral, or fungal infection of one or both sides of the lungs that causes lung alveoli to fill up with fluid or pus, which is usually diagnosed with chest x-rays. This work investigates opportunities for applying machine learning solutions for automated detection and localization of pneumonia on chest x-ray images. We propose an ensemble of two convolutional neural networks, namely RetinaNet and Mask R-CNN for pneumonia detection and localization. We validated our solution on a recently released dataset of 26,684 images from Kaggle Pneumonia Detection Challenge and were score among the top 3{\%} of submitted solutions. With 0.793 recall, we developed a reliable solution for automated pneumonia diagnosis and validated it on the largest clinical database publicity available to date. Some of the challenging cases were additionally examined by a team of physicians, who helped us to interpret the obtained results and confirm their practical applicability.},
author = {Sirazitdinov, Ilyas and Kholiavchenko, Maksym and Mustafaev, Tamerlan and Yixuan, Yuan and Kuleev, Ramil and Ibragimov, Bulat},
doi = {10.1016/j.compeleceng.2019.08.004},
file = {:C$\backslash$:/Users/Saeed Ullah/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sirazitdinov et al. - 2019 - Deep neural network ensemble for pneumonia localization from a large-scale chest x-ray database.pdf:pdf},
issn = {00457906},
journal = {Computers and Electrical Engineering},
keywords = {CXR, Pneumonia localization,Chest x-ray,Convolutional neural networks,Deep learning,Lung opacity detection,Pneumonia detection},
pages = {388--399},
publisher = {Elsevier Ltd},
title = {{Deep neural network ensemble for pneumonia localization from a large-scale chest x-ray database}},
url = {https://doi.org/10.1016/j.compeleceng.2019.08.004},
volume = {78},
year = {2019}
}
@phdthesis{Hariharan2015a,
abstract = {Object recognition in computer vision comes in many flavors, two of the most popular being object detection and semantic segmentation. Object detection systems detect every instance of a category in an image, and coarsely localize each with a bounding box. Semantic segmentation systems assign category labels to pixels, thus providing pixel-precise localization but failing to resolve individual instances of the category. We argue for a richer output: recognition systems should detect individual instances of a category and provide pixel precise segmentations for each, a task we call Simultaneous Detection and Segmentation or SDS. We describe approaches to this task that leverage convolutional neural networks for precise localization. We also show that the techniques we develop are also effective for other tasks such as segmenting the parts of a detected object or localizing its keypoints. These are our first steps towards a recognition system that goes beyond category labels and coarse bounding boxes to precise, detailed descriptions of objects in images.},
author = {Hariharan, Bharath},
file = {:C$\backslash$:/Users/Saeed Ullah/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hariharan - 2015 - Beyond Bounding Boxes Precise Localization of Objects in Images.pdf:pdf},
pages = {39},
school = {University of California, Berkeley},
title = {{Beyond Bounding Boxes : Precise Localization of Objects in Images}},
url = {http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.pdf},
year = {2015}
}
