
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL E:\aidd_new\aidd\reports\journal_papers\Paper_Article\document_2.tex         Fri Jul 10 11:10:21 2020
%DIF ADD E:\aidd_new\aidd\reports\journal_papers\Paper_Article_R1\document_2_R1.tex   Fri Sep 25 10:50:18 2020
%% 
%% Copyright 2007, 2008, 2009 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references
%% SP 2008/03/01

\documentclass[preprint,9pt]{elsarticle}

%% Use the option review to obtain double line spacing
%documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times,authoryear]{elsarticle}
%% \documentclass[final,1p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,3p,times,authoryear]{elsarticle}
%%\documentclass[final,3p,times,twocolumn,authoryear]{elsarticle}
%% \documentclass[final,5p,times,authoryear]{elsarticle}
%% \documentclass[final,5p,times,twocolumn,authoryear]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amsmath,amssymb,bm}
%\usepackage[dvips,colorlinks=true,citecolor=green]{hyperref}
\usepackage[colorlinks=true,citecolor=green]{hyperref}
%% my added packages
\usepackage{float}
\usepackage{csquotes}
\usepackage{verbatim}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs} % for nice tables
\usepackage{csvsimple} % for csv read
\usepackage{graphicx}
%\usepackage[outdir=//odroid-sensors/sensors/aidd/reports/journal_papers/MSSP_Paper/Figures/]{epstopdf}
%\usepackage{breqn}
\usepackage{multirow}
% matrix command 
\newcommand{\matr}[1]{\mathbf{#1}} % bold upright (Elsevier, Springer)
% vector command 
\newcommand{\vect}[1]{\mathbf{#1}} % bold upright (Elsevier, Springer)
\newcommand{\ud}{\mathrm{d}}
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\veca}[2]{\mathbf{#1}{#2}}
\renewcommand{\bm}[1]{\mathbf{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
% limits underneath
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\graphicspath{{Figures/}{//odroid-sensors/sensors/aidd/reports/journal_papers/MSSP_Paper/Figures/}}
%\graphicspath{ {Graphics/Figures/} }
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}
%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}
\journal{Mechanical Systems and Signal Processing}
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFaddtex}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdeltex}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
\providecommand{\DIFmodbegin}{} %DIF PREAMBLE
\providecommand{\DIFmodend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF HYPERREF PREAMBLE %DIF PREAMBLE
\providecommand{\DIFadd}[1]{\texorpdfstring{\DIFaddtex{#1}}{#1}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{\texorpdfstring{\DIFdeltex{#1}}{}} %DIF PREAMBLE
\newcommand{\DIFscaledelfig}{0.5}
%DIF HIGHLIGHTGRAPHICS PREAMBLE %DIF PREAMBLE
\RequirePackage{settobox} %DIF PREAMBLE
\RequirePackage{letltxmacro} %DIF PREAMBLE
\newsavebox{\DIFdelgraphicsbox} %DIF PREAMBLE
\newlength{\DIFdelgraphicswidth} %DIF PREAMBLE
\newlength{\DIFdelgraphicsheight} %DIF PREAMBLE
% store original definition of \includegraphics %DIF PREAMBLE
\LetLtxMacro{\DIFOincludegraphics}{\includegraphics} %DIF PREAMBLE
\newcommand{\DIFaddincludegraphics}[2][]{{\color{blue}\fbox{\DIFOincludegraphics[#1]{#2}}}} %DIF PREAMBLE
\newcommand{\DIFdelincludegraphics}[2][]{% %DIF PREAMBLE
\sbox{\DIFdelgraphicsbox}{\DIFOincludegraphics[#1]{#2}}% %DIF PREAMBLE
\settoboxwidth{\DIFdelgraphicswidth}{\DIFdelgraphicsbox} %DIF PREAMBLE
\settoboxtotalheight{\DIFdelgraphicsheight}{\DIFdelgraphicsbox} %DIF PREAMBLE
\scalebox{\DIFscaledelfig}{% %DIF PREAMBLE
\parbox[b]{\DIFdelgraphicswidth}{\usebox{\DIFdelgraphicsbox}\\[-\baselineskip] \rule{\DIFdelgraphicswidth}{0em}}\llap{\resizebox{\DIFdelgraphicswidth}{\DIFdelgraphicsheight}{% %DIF PREAMBLE
\setlength{\unitlength}{\DIFdelgraphicswidth}% %DIF PREAMBLE
\begin{picture}(1,1)% %DIF PREAMBLE
\thicklines\linethickness{2pt} %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\framebox(1,1){}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\line( 1,1){1}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,1){\line(1,-1){1}}}% %DIF PREAMBLE
\end{picture}% %DIF PREAMBLE
}\hspace*{3pt}}} %DIF PREAMBLE
} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbegin}{\DIFaddbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddend}{\DIFaddend} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbegin}{\DIFdelbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelend}{\DIFdelend} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbegin}{\DIFOaddbegin \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbegin}{\DIFOdelbegin \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbeginFL}{\DIFaddbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddendFL}{\DIFaddendFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbeginFL}{\DIFdelbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelendFL}{\DIFdelendFL} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbeginFL}{\DIFOaddbeginFL \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbeginFL}{\DIFOdelbeginFL \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
%DIF LISTINGS PREAMBLE %DIF PREAMBLE
\RequirePackage{listings} %DIF PREAMBLE
\RequirePackage{color} %DIF PREAMBLE
\lstdefinelanguage{DIFcode}{ %DIF PREAMBLE
%DIF DIFCODE_UNDERLINE %DIF PREAMBLE
  moredelim=[il][\color{red}\sout]{\%DIF\ <\ }, %DIF PREAMBLE
  moredelim=[il][\color{blue}\uwave]{\%DIF\ >\ } %DIF PREAMBLE
} %DIF PREAMBLE
\lstdefinestyle{DIFverbatimstyle}{ %DIF PREAMBLE
	language=DIFcode, %DIF PREAMBLE
	basicstyle=\ttfamily, %DIF PREAMBLE
	columns=fullflexible, %DIF PREAMBLE
	keepspaces=true %DIF PREAMBLE
} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim}{\lstset{style=DIFverbatimstyle}}{} %DIF PREAMBLE
\lstnewenvironment{DIFverbatim*}{\lstset{style=DIFverbatimstyle,showspaces=true}}{} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}
	\begin{frontmatter}
		\addcontentsline{toc}{section}{References}
		%% Title, authors and addresses
		%% use the tnoteref command within \title for footnotes;
		%% use the tnotetext command for theassociated footnote;
		%% use the fnref command within \author or \address for footnotes;
		%% use the fntext command for theassociated footnote;
		%% use the corref command within \author for corresponding author footnotes;
		%% use the cortext command for theassociated footnote;
		%% use the ead command for the email address,
		%% and the form \ead[url] for the home page:
		%% \title{Title\tnoteref{label1}}
		%% \tnotetext[label1]{}
		%% \author{Name\corref{cor1}\fnref{label2}}
		%% \ead{email address}
		%% \ead[url]{home page}
		%% \fntext[label2]{}
		%% \cortext[cor1]{}
		%% \address{Address\fnref{label3}}
		%% \fntext[label3]{}

		\title{Full Wavefield Processing by Using FCN for Delamination Detection}

		%% use optional labels to link authors explicitly to addresses:
		%% \author[label1,label2]{}
		\address[IFFM]{Institute of Fluid Flow Machinery, Polish Academy of Sciences, Poland}

		\author{Abdalraheem A. Ijjeh\fnref{IFFM}}
		\author{Saeed Ullah \fnref{IFFM}}
		\author{Pawel Kudela\corref{cor1}\fnref{IFFM}}
		\ead{pk@imp.gda.pl}
		%\ead{pfiborek@imp.gda.pl}
		%\author{Tomasz Wandowski \fnref{IFFM}}	

		\cortext[cor1]{Corresponding author}

		\begin{abstract}
		\DIFdelbegin %DIFDELCMD < \input{abstract}
%DIFDELCMD < 		%%%
\DIFdelend \DIFaddbegin \input{diff_abstract_2}
		\DIFaddend \end{abstract}

		\begin{keyword}
			%% keywords here, in the form: keyword \sep keyword
			Lamb waves \sep structural health monitoring \sep non-destructive testing \sep delamination identification \sep deep learning \sep  fully convolutional neural networks 
			%% PACS codes here, in the form: \PACS code \sep code

			%% MSC codes here, in the form: \MSC code \sep code
			%% or \MSC[2008] code \sep code (2000 is the default)

		\end{keyword}

	\end{frontmatter}
	%% main text

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Composite materials have a wide range of applications in various industries, due to their characteristics such as high strength, low density, resistance to fatigue and corrosion.  
However, damage can occur in composite materials due to impacts resulting from the lack of reinforcement in the out-of-plane direction~\cite{Francesconi2019}.
In particular, laminated composite materials are more sensitive to damage in the form of delamination due to weak transverse tensile and interlaminar shear strengths.
Delamination can alter the compression strength of composite laminate, and gradually affect the composite to encounter failure by buckling. 
Delaminations can seriously decrease the performance of composite structures, accordingly, delamination detection in its early stages can significantly help to avoid catastrophic structural collapses.

One of the conventional techniques for damage identification for non-destru\-ctive testing (NDT) involves arrays of transducers that can be mounted or embedded in the structures for registering the response of the guided wave propagation.
%However, damage identification regarding structures with curved and deformable geometry can be inaccurate when using an array of transducers.
However, damage influence maps resulted from processing of signals registered by the array of transducers have low resolution, due to the small number of sensing points. 
Accordingly, this issue of low-resolution damage influence map can be solved by utilising a Scanning Laser Doppler Vibrometry (SLDV), which is a non-contact technique dedicated to full wavefield measurements of vibration and guided wave propagation.
%Moreover, the delamination location plays a key role in its identification i.e. delamination located at the edges or the corners of a structure are considered difficult scenarios due to a reflected signals from these locations have similar characteristics of those reflected from damage.
%Therefore, utilising SLDV for acquiring signals to produce a higher resolution influence map will be more beneficial than only using a transducers array. 
The measurements are conducted on a dense mesh of measurement points spanned over the area of the investigated structure.
Consequently, SLDV produces a full wavefield of measurements with high resolution of damage influence maps which can significantly improve the process of damage detection and localisation~\cite{Michaels2007,Park2014,Tian2015a,Kudela2015}.
Full wavefield processing techniques even allow for damage size estimation~\cite{Girolamo2018a,Kudela2018} which is difficult to perform in case of transducer arrays, especially for composite structures.
Therefore, the latter methods are evaluated mostly for damage detection and localisation in metallic structures~\cite{Michaels2008,Huang2018a,Wang2020}.

Certain algorithms such as the time reversal algorithm can benefit from combining piezoceramic transducers (as actuators) with SLDV for sensing~\cite{Girolamo2018a, Miniaci2019}.

Conventional damage detection and localisation methods focus on patterns extraction from registered measurements and accordingly make decisions based on these patterns~\cite{Gul2009}. 
Moreover, conventional methods for pattern recognition require feature selection and classification (handcrafted features). 
These conventional methods can perform efficient damage detection, however, these methods depend on selected features from their scope of measurement.
Accordingly, introducing new patterns will cause them to fail in detecting the damage.
Furthermore, these methods could fail in detecting damage when dealing with big data requiring a complex computation of damage features~\cite{Gulgec2019}.
Perhaps the most challenging part for damage detection is determining the unknown relationship between registered measurements and damage patterns~\cite{Gulgec2019}. 

The accelerated progress in the field of artificial intelligence (AI) technologies in recent years, and mainly in deep learning, revealed new dimensions for solving problems and offered the opportunity for being implemented and integrated with the NDT and further with structural health monitoring (SHM) approaches.
Therefore, issues regarding data preprocessing and feature extraction can be handled when applying deep learning techniques. 
Nowadays, end-to-end approaches are developed, in which the whole unprocessed data are fed into the model, hence, it will learn by itself to recognise the patterns and detect the damage.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DIFaddbegin \DIFadd{Deep learning techniques have widely been utilised for the inspection and maintenance of civil infrastructure and have shown very promising results~\mbox{%DIFAUXCMD
\cite{cha2017deep, lin2017structural, liu2019computer, beckman2019deep, choi2019sddnet}}\hspace{0pt}%DIFAUXCMD
. 
It has also been successfully applied for various fault diagnosis based tasks in rotating machinery~\mbox{%DIFAUXCMD
\cite{janssens2016convolutional}}\hspace{0pt}%DIFAUXCMD
. 
For instance, Cha et al.~\mbox{%DIFAUXCMD
\cite{cha2017deep} }\hspace{0pt}%DIFAUXCMD
proposed a computer vision-based method using deep Convolutional Neural Network (DCNN) for the detection of concrete cracks. 
They compared their Convolutional Neural Network (CNN) based approach with traditional edge detection techniques such as Sobel and Canny methods and showed that their proposed model achieved quite better results and is very suitable for finding concrete cracks in realistic situations. 
Lin et al.~\mbox{%DIFAUXCMD
\cite{lin2017structural} }\hspace{0pt}%DIFAUXCMD
developed an automatic damage feature extraction DCNN model and their results showed that DCNN outperformed conventional methods in realistic situations. 
Choi and Cha~\mbox{%DIFAUXCMD
\cite{choi2019sddnet} }\hspace{0pt}%DIFAUXCMD
developed an encoder-decoder based semantic segmentation damage detection network (SDDNet), a real-time segmentation method based on CNN. 
SDDNet was inspired by a DenseNet and DeepLabV3+~\mbox{%DIFAUXCMD
\cite{chen2018encoder}}\hspace{0pt}%DIFAUXCMD
. 
Liu et al.~\mbox{%DIFAUXCMD
\cite{liu2019computer} }\hspace{0pt}%DIFAUXCMD
applied the U-Net network structure based on fully convolutional networks (FCN) for the purpose of identifying the locations of cracks in the raw input images of civil infrastructure under different conditions such as messy background, illumination, width of the cracks, etc. 
They compared their trained U-Net model with DCNN based method and found that the U-Net based model shown better performance as compared to DCNN in various circumstances.  
Beckman et al.~\mbox{%DIFAUXCMD
\cite{beckman2019deep} }\hspace{0pt}%DIFAUXCMD
proposed a faster region-based CNN (Faster R-CNN)-based concrete spalling damage detection approach with the use of an inexpensive depth sensor for quantifying multiple instances of spalling. The Faster R-CNN enables the detection, localisation, and quantification of the amount of concrete spalled from a concrete element automatically. 
The Faster R-CNN provides a bounding box for the detection and localisation of defects. 
Janssens et al. ~\mbox{%DIFAUXCMD
\cite{janssens2016convolutional} }\hspace{0pt}%DIFAUXCMD
developed a CNN based feature learning method for autonomously detecting different faults in rotating machinery with the use of vibration data. 
The input to the CNN modal was a discrete Fourier Transform of the two accelerometers. 
They compared their CNN based model with the classical feature-engineering based method which employs manually engineered features and a random forest classifier. 
They showed that their CNN based model outperformed the classical feature-engineering based approach. 
}

%DIF > %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\DIFadd{Besides the widespread applications of deep learning in civil and rotating machinery domains, deep learning is still less explored for the purpose of delamination detection in composite materials.
}\DIFaddend In the following, methods for damage size estimation based on machine learning and deep learning techniques are presented which are targeted in the field of SHM/NDT.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
One of the earliest work for delamination location and size assessment in composite structures using deep learning techniques was performed by Islam et al.~\cite{islam1994damage}. 
They have trained a neural network model with frequencies for the first five modes obtained from modal analysis data. 
The data was acquired by piezoceramic sensors in both damaged and undamaged composite beams.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Okafor et al.~\cite{okafor1996delamination} applied a feed-forward backpropagation neural network to assess the delamination size in a smart composite beam. 
For training the neural network model, authors used delamination sizes and corresponding the first four modal frequencies. 
The trained model was tested with new cases of delamination using the first four normalized frequencies of test cases as an input to the network. 
Their model predicted the delamination size between 0.22~cm and 0.82~cm successfully.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Moreover, Chakraborty et al.~\cite{chakraborty2005artificial} proposed a neural network model for detecting delamination shape, size and location in a fibre-reinforced plastic composite laminate.
Authors used natural frequencies as inputs and the corresponding size, shape and location of delamination as outputs of the model. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Authors in ~\cite{roseiro2005neural}  proposed a damage detection method in laminated composite plates to locate and quantify damage through utilising the electrical potential of piezoelectric sensors and artificial neural networks. 
The model was trained using the Levenberg-Marquardt algorithm. High accuracy of damage location was achieved.
But tests were performed only based on the numerical model.  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Sammons et al.~\cite{sammons2016segmenting}, utilised X-ray computed tomography for estimating the delaminations in a carbon fibre reinforced polymer (CFRP). 
For this purpose, they utilised a \DIFdelbegin \DIFdel{convolutional neural network (CNN ) }\DIFdelend \DIFaddbegin \DIFadd{CNN }\DIFaddend for performing image segmentation of the defected input images to estimate the delaminations. 
Their CNN was capable of identifying and quantifying small delaminations. 
Unfortunately, the proposed network architecture could not recognise delaminations with large sizes.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Further, De Fenza et al.~\cite{de2015application} proposed a method for damage detection in plates made of aluminium alloys and composite materials using Lamb waves by a neural network model.
The model was used for automatic feature extraction in conjunction with probability ellipse based method. 
The neural network model and probability ellipse method were applied for computing the damage index (DI). 
It was derived by comparing the differences in the measured  Lamb waves before and after a damage occurrence. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Ewald et al.~\cite{ewald2019deepshm} proposed a deep learning technique for SHM on guided Lamb waves \enquote{DeepSHM}. 
They pre-processed the sensor signal response through applying wavelet transform to obtain the wavelet coefficient matrix (WCM), which is fed into the CNN for training to acquire the neural weights. 
They achieved different classification accuracies ranging from \(17\%\) to \(99.9\%\).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Authors in~\cite{Melville2018} proposed a technique for damage detection in thin metal plates (aluminum and steel), using full wavefield data acquired by SLDV. 
Using this data to train a deep neural network of 4 hidden layers including 2 convolutional layers for features extraction and 2 fully connected layers. 
Their technique show good results when compared with traditional support vector machine (SVM) methods.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Furthermore, Esfandabadi et al.~\cite{esfandabadideep} applied 20 layers based very-deep super-resolution (VDSR) architecture (VDSR is a variant of CNN), on a guided ultrasonic wavefield for enhancing the quality of image resolution and quality of the acquired wavefield. 
VDSR was applied in conjunction with compressive sensing theory with the aim of reducing the acquisition time of the ultrasonic wavefield.
The model was trained on \(652\) wavefield images (\(326\) with defect and \(326\) without defects) generated by piezoelectric transducers and acquired by SLDV. 
Authors have used various aluminium and CFRP plates to prepare the dataset.
It was concluded that high-resolution images can be obtained, even when only the 10\% of the original scan points were retained
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Motivated by high potentials of deep learning techniques, in this work, we are exploring the feasibility of applying such techniques for detecting delaminations in CFRP plates. 
One of the key points of our work is the computation of a large dataset of full wavefield of propagating guided waves by using the parallel version of the time domain spectral element method~\cite{Kudela2020}. 
Numerically generated data resembles measurements acquired by SLDV. 

For our knowledge, it is the first time, a large full wavefield dataset of propagating guided waves will be fed as an input to deep neural networks with the aim of delamination size estimation.

In this work, we are presenting a pixel-wise segmentation model which is capable of detecting and localising the delamination, through segmentation of the input image into damaged and undamaged parts.
For this purpose, we have created a deep learning model based on a fully convolutional neural network (FCN)~\cite{long2015fully}.
FCN is considered as a type of CNN, in which the densely connected network is replaced by fully convolutional layers. 
FCNs can be trained end-to-end and pixels-to-pixels, without the need for performing a process of feature extraction. 
Moreover, the pixel-wise segmentation model enables the precise shape and size estimation of defects.
The capabilities and potentials of the proposed method are compared to the conventional wavefield signal processing method i.e. adaptive wavenumber filtering~\cite{Kudela2015,Radzienski2019}.
The quantitative comparison was performed by using intersection over \DIFdelbegin \DIFdel{the union }\DIFdelend \DIFaddbegin \DIFadd{union (IoU) }\DIFaddend of detected delamination area with respect to the ground truth. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methodology}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DIFdelbegin %DIFDELCMD < \input{dataset}
%DIFDELCMD < \input{Signal_processing_strategy}
%DIFDELCMD < \input{Adaptive_wavenumber_filtering}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \input{diff_dataset}
\input{diff_Signal_processing_strategy}
\input{diff_Adaptive_wavenumber_filtering}
\DIFaddend %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Fully Convolutional Network approach}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this section, a deep learning approach for delamination detection in composite materials is presented. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Data preprocessing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
It should be noted that the output from the wave propagation model is in the form of a 3D matrix which contains amplitudes of propagating waves at location \((x, y)\) and time \(t\). We can look at it as a set of frames of propagating waves at discrete time moments \(t_k\).

The data preprocessing as it is indicated in Fig.~\ref{fig:sig_proc_strategy} include a step of computation of root mean square value:
\begin{equation}
	\hat{s}(x,y) = \sqrt{\frac{1}{N}\sum_{k=1}^{N} s(x,y,t_k)^2}
	\label{eq:rms}
\end{equation}
where the number of sampling points \(N\) was 512.
In this way, the dataset was collapsed to 475 2D matrices in which amplitudes are stored as double-precision values.
The next step was the conversion of these matrices to greyscale images (colour image quantisation).
Colour scale values of obtained images vary between (\(0 - 255\)) hence normalization
to a range of (\(0-1\)) was applied to \DIFdelbegin \DIFdel{enhance the optimizerfunction during the learning process}\DIFdelend \DIFaddbegin \DIFadd{improve convergence of gradient descent algorithm (Adam optimizer)}\DIFaddend . 

Furthermore, data augmentation was achieved by flipping images horizontally, vertically and diagonally. 
It increased the dataset size four times -- \(1900\) images were produced.
Such data augmentation can enhance the learning process by enabling the model to learn and recognise new complex patterns.

The data set was split into two portions:  \(80\%\) for the training set and \(20\%\) for the testing set.
Additionally, the validation set was created as a \(20\%\) of the training set.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DIFdelbegin %DIFDELCMD < \input{section_fully_convolutional_networks}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \input{diff_section_fully_convolutional_networks}
\DIFaddend %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DIFdelbegin %DIFDELCMD < \input{FCN_models}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \input{diff_FCN_models}
\DIFaddend %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DIFdelbegin %DIFDELCMD < \input{results_and_discussions}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \input{diff_results_and_discussions}
\DIFaddend %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DIFdelbegin %DIFDELCMD < \input{Conclusions}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \input{diff_Conclusions}
\DIFaddend \clearpage	
%\appendix
\section*{Acknowledgements}
The research was funded by the Polish National Science Center under grant agreement no 2018/31/B/ST8/00454.
We would like to acknowledge dr Maciej Radzienski for providing the experimental data of full wavefield measured by SLDV.

\bibliography{MSSP_paper1}
\bibliographystyle{num_order}
\end{document}


