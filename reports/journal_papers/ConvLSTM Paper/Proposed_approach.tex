\subsection{Deep learning models}
\label{proposed_approach}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this work, we developed two end-to-end deep learning models utilising full wavefield frames of Lamb wave propagation for delamination identification in CFRP materials as presented in Fig.~\ref{fig:proposed_models}.
The developed models have a scheme of many-to-one sequence prediction, which takes \(n\) number of frames representing the full wavefield propagation through time and their interaction with the delamination to extract the damage features, and finally predict the delamination location, shape, and size in a single output image.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure} [!h]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\centering
		\includegraphics[width=.2\textheight]{figure3a.png}
		\caption{Model-\RNum{1}} % : Convolutional LSTM model.
		\label{fig:convlstm_model}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.49\textwidth}
		\centering
		\includegraphics[width=.2\textheight]{figure3b.png}
		\caption{Model-\RNum{2}} % : Time distributed AE model.
		\label{fig:AE_convlstm}
	\end{subfigure}
	\caption{The architecture of the proposed deep learning models.}
	\label{fig:proposed_models}
\end{figure} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The first proposed model presented in Fig.~\ref{fig:convlstm_model} 
consists of three ConvLSTM layers that can process time series and computer vision tasks.
The first ConvLSTM layer has \(12\) filters, second layer has \(6\) filters and third layer has \(12\) filters.
The kernel size of the ConvLSTM layers was set to (\(3\times3\)) with a stride of \(1\), padding was set to "same" which makes the output the same as the input in the case of stride \(1\).
Furthermore, a \(\tanh\) (the hyperbolic tangent) activation function was used within the ConvLSTM layers that output values in a range between (\(-1\) and \(1\)).
Moreover, we applied a Batch Normalization technique~\cite{Santurkar2018} after the first two ConvLSTM layers.  

In the second model presented in Fig.~\ref{fig:AE_convlstm} we applied an autoencoder technique (AE) which is well-known for extracting spatial features.
The idea of AE is to compress the input data within the encoding process then learn how to reconstruct it back from the reduced encoded representation (latent space) to a representation that is as close to the original input as possible. 
In this model, we have investigated the use of AE to process a sequence of input frames to perform image segmentation.
Therefore, a Time Distributed layer presented in Fig.~\ref{fig:TD} was introduced to the model, in which it distributes the input frames into the AE layers in order to process them independently.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.5\textwidth]{figure4.png}
	\caption{Flow of input frames using Time distributed layer.}
	\label{fig:TD}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In general, an AE consists of three parts: the encoder, the bottleneck, and the decoder.
The encoder is responsible for learning how to reduce the input dimensions and compress the input data into an encoded representation.
In Fig.~\ref{fig:AE_convlstm}, the encoder part consists of four levels of downsampling. 
The purpose of having different scale levels is to extract feature maps from the input image at different scales.
Every level at the encoder consists of two 2D convolution operations followed by a Batch Normalization then a Dropout is applied. 
Furthermore, at the end of each level a Maxpooling operation is applied to reduce the dimensionality of the inputs. 
The bottleneck presented in Fig.~\ref{fig:AE_convlstm} has the lowest level of dimensions of the input data, further it consists of two 2D convolution operations followed by a Batch Normalization.
The decoder part presented in Fig.~\ref{fig:AE_convlstm}, is responsible for learning how to restore the original dimensions of the input.
The decoder part consists of two 2D convolutional operations followed by Batch Normalization and Dropout, and an upsampling operation is applied at the end of each decoder level to retrieve the dimensions of its inputs.
Skip connections linking the encoder with the corresponding decoder levels were added to enhance the features extraction process.
The outputs of the decoder were forwarded into the ConvLSTM2D layer to learn long-term spatiotemporal features.

In both models, we applied a 2D convolutional layer as the final output layer followed by a sigmoid activation function which outputs values in a range from \((0,1)\) to indicate the delamination probability.
Consequently, a threshold value must be chosen to classify the output into a damaged represented by (\(1\)) or undamaged represented by (\(0\)).
Hence, we set the threshold value to (\(0.5\)) to exclude all values below the threshold by considering them as undamaged and taking only those values greater than the threshold to be considered as damaged.
%The reason for selecting such threshold value to the sigmoid activation function is explained in our previous research work~\cite{Ijjeh2021}.
%Further, Adadelta~\cite{zeiler2012adadelta} optimization method with binary cross-entropy (BCE) was applied to the first model, whereas in the second model, Adam optimizer~\cite{Kingma2014} with BCE was applied.

For evaluating the performance of the proposed models, the mean 
intersection over union \(IoU\) (Jaccard index) was applied as the accuracy metric. 
\(IoU\) is estimated by determining the intersection
area between the ground truth and the predicted output. 
Further, we have two output classes (damaged and undamaged), the \(IoU\) was calculated for the damaged class only. 
Equation~(\ref{eqn:iou}) illustrated the \(IoU\) metric: 
\begin{equation}
	IoU=\frac{Intersection}{Union}=\frac{\hat{Y} \cap Y}{\hat{Y} \cup Y}
	\label{eqn:iou}
\end{equation}
where \(\hat{Y}\) is the predicted output, and \(Y\) is the ground truth.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{table}[]
%	\centering
%	\caption{Models parameters}
%	\label{tab:parmeters}
%	\begin{tabular}{ccc}
%		\hline
%		\multirow{2}{*}{Parameter} & \multicolumn{2}{c}{Model}               
%		\\ 
%		\cline{2-3} 
%		& 1  & 2
%		\\ \hline
%		Optimizer &	Adadelta~\cite{zeiler2012adadelta} &  Adam~\cite{Kingma2014}              
%		\\
%		Batch size & 2  & 1                
%		\\
%		Dropout  & 0.0  & 0.2                
%		\\
%		Learning rate & 1.0 & 0.01             
%		\\
%		Loss function  & \multicolumn{2}{c}{Binary cross entropy} 
%		\\ \hline
%	\end{tabular}
%\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%