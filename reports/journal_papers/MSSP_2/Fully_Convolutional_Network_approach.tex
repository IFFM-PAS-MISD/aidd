%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Fully Convolutional Network approach}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%In this section, a deep learning approach for delamination detection in composite materials is presented. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data preprocessing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The wave propagation model produces outputs in the form of a 3D matrix which contains the propagating waves' amplitudes at location \((x, y)\) and time \(t\). 
Therefore, it can be seen as a set of frames of waves which propagates at a discrete-time moments \(t_k\).

Furthermore, the data preprocessing include a step of computation of root mean square (RMS) value as shown in Eqn.~(\ref{eq:rms}), where \(N=512\) represents the sampling points.
\begin{equation}
	\hat{s}(x,y) = \sqrt{\frac{1}{N}\sum_{k=1}^{N} s(x,y,t_k)^2}
	\label{eq:rms}
\end{equation}
As a result, a 475 2D matrices were generated in which the amplitudes were stored as double-precision values.
Next, we have converted these matrices into grayscale images (colour image quantization).

To enhance the performance of the optimizer during the training process, the colour scale values were normalized to a range of (\(0-1\)) instead of the initial scale which was in a range of (\(0 - 255\)).	
Furthermore, we have applied data augmentation on the dataset by flipping the images horizontally, vertically and diagonally. 
As a result, the dataset size increased four times -- \(1900\)  images were produced.
By doing so, we can enhance the learning process by enabling the model to learn and recognise new and different complex patterns.
We have split the dataset into two portions:  \(80\%\) for the training set and \(20\%\) for the testing set.
Moreover, a cross-validation (CV) method was applied to the training set to reduce the overfitting which happens when the model is able to fit on the training data, while it poorly fit on the new unseen data.
In other words, the model only learns the patterns of the training data therefore the model will not generalise well. 
Fig.~\ref{fig:Cross_validation} illustrates as the CV method in which  we have applied a technique called K-fold CV.
In this technique, we have split the training set into \(K\) small sets (folds), hence the name K-folds. 
Therefore, we iterate over the training set K rounds.
During each round, the model uses  \(K-1\) folds for training and the remaining fold is used for validation. 
In our models, we choose \(K=5\), therefore, we have \(5\) rounds of training. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
For each iteration, we compute the performance of the model.
Finally, we compute the cross-validation performance for all iterations as illustrated in Eqn.~(\ref{eq:cv_performance}) as a mean value over the K performance estimations of the validation fold set.
The main advantage of the K-fold CV method versus a regular train/test split is to reduce the overfitting by utilising data more efficiently as every data sample is used in both training and validation. 
Therefore, using by using this method we aim to improve the model ability to generalise and reduce the overfitting.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{equation}
Final \ Performance = \frac{1}{K}\sum_{i=1}^{K}Performace
\label{eq:cv_performance}
\end{equation}
\begin{figure}
	\centering
	\includegraphics[scale=1.0]{cross_validation.png}
	\caption{K-fold Cross validation, K=\(5\).}
	\label{fig:Cross_validation}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
