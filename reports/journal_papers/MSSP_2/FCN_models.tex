\subsubsection{Residual UNet model}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Residual UNet (Res-UNet) model is based on the residual learning~\cite{He2016} and the UNet technique~\cite{Ronneberger2015}. 
It is a well-known architecture that performs a biomedical segmentation based on encoder-decoder. 
The Res-UNet has a U-shape convolutional network that is based on encoder-decoder style. 
The encoder (contracting) path is responsible for capturing the detailed context of an input image, while the decoder (expansive) path is responsible for enabling a precise localisation. 
Hence, to maintain the spatial and contextual information from the previous layers from being lost residual connections were added at two levels:
\begin{itemize}
	\item at each step of the encoder and decoder paths,
	\item between the encoder parts and their corresponding decoder parts (skip connections) which ensures that the feature maps which were learned during the downsampling will be utilized in the reconstruction. 
\end{itemize}
The applied Res-UNet architecture is presented in Fig.~\ref{fig:Unet}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The encoder part holds several downsampling (Max-pool) blocks. 
Each block applies two convolutional layers followed by a (\(2\times2\)) max pooling with a (\(2\times2\)) strides that picks the maximum value in a local pool filter in one feature map (or \(n\)-feature maps), resulting in a reduction in the dimension of feature maps~\cite{Lecun2015}, consequently, reducing computation complexity.
Each convolutional layer performs (\(3\times3\)) convolution operations, followed by batch normalization (BN) then a Relu is applied.
Moreover, the number of convolutional filters is doubled after each downsampling block therefore the model can learn complex patterns effectively. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The bottleneck layer lies in between the encoder and the decoder as a joining point in the deepest layer in the model.
The bottleneck contains two convolutional layers, with \(1024\) filters which helps the model to learn and recognize the complex patterns.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The decoder consists of several upsampling blocks. 
Each upsampling block passes the input into two convolution layers as in the downsampling block followed by a transmission up layer consisting of a transposed convolutional layer (upsampling). 
The purpose of upsampling is to retrieve the dimensions and increase the resolution.
Transposed convolutional layer differs from the regular upsampling function, by introducing learnable parameters regarding the transposed convolution filters that enhance the learning process of the model. 
Moreover, after each upsampling operation, the number of feature maps used by convolutional layer is reduced by half to keep the model symmetrical. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure} [h!]
	\begin{center}
		\includegraphics[scale=1.0]{RES_UNET.png}
	\end{center}
	\caption{Res-UNet architecture.} 
	\label{fig:Unet}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{VGG16 encoder-decoder}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this model, we address the use of VGG16~\cite{Simonyan2015} architecture as a backbone encoder to the UNet~\cite{Ronneberger2015} technique.
VGG16 is composed of 13 convolutional layers, pooling layers and \(3\) dense layers, and it is used for classification purposes.
We removed the dense layers from the model, and we applied VGG16 of 13 convolutional layers as encoder-decoder for pixel-wise image segmentation.
Figure~\ref{vgg16} presents the architecture of VGG16 encoder-decoder model. 
The model has a U-shape of two parts: encoder and decoder.
The encoder consists of \(5\) convolutional blocks with a total \(13\)  (\(3\times3\)) convolutional layers followed by BN and activation function Relu.
A Max pool operation with pool size of (\(2\times2\)) followed by dropout is performed after each convolutional block.  
The upsampling path is introduced to recover spatial resolution, it also has \(5\) convolutional blocks with a total \(13\) \((3\times 3)\) convolutional layers.
For upsampling, bilinear interpolation with (\(2\times2\)) kernel size is applied.
Skip connections were added between downsampling blocks and the corresponding upsampling blocks in order to enhance recovering fine-grained details by enabling feature re-usability from earlier layers.
\begin{figure} [h!]
	\begin{center}
		\includegraphics[scale=1.0]{VGG16_encoder_decoder.png}
	\end{center}
	\caption{VGG16 encoder decoder architecture.} 
	\label{vgg16}
\end{figure}
\input{fcn_densenet_model}