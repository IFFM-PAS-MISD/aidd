\subsubsection{U-Net based model}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
U-Net is a well-known architecture based on encoder-decoder scheme was introduced by Ronneberger et al.~\cite{Ronneberger2015} for biomedical image segmentation. 
The principle function of the encoder is to capture the context of an input image, while the decoder is responsible for enabling a precise localisation. 
%U-net is composed of three parts: The downsampling section, The bottleneck, and the upsampling section. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The encoder part holds several downsampling blocks. 
Each block takes an input applies two convolutional layers followed by a (\(2\times2\)) max pooling with a (\(2\times2\)) strides that picks the maximum value in a local pool filter in one feature map (or \(n\)-feature maps), resulting in a reduction in the dimension of feature maps~\cite{Lecun2015}, consequently, reducing computation complexity.
Each convolutional layer performs (\(3\times3\)) convolution operations, followed by Relu activation function.
Furthermore, to enhance the model training performance we applied batch normalization (BN)~\cite{Ioffe2015} after each convolutional layer.
Moreover, the number of convolutional filters is doubled after each downsampling block therefore the model can learn complex patterns effectively. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The bottleneck layer meddles between the encoder and the decoder as a joining point is the deepest layer in the model.
The bottleneck contains two convolutional layers, with 256 filters which helps the model to learn and recognize the complex patterns.
%It composed of two (\(3\times3\)) convolution layers followed by (\(2\times2\)) up convolution layer (Transpose convolution).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The decoder consists of several upsampling blocks. 
Each upsampling block passes the input into two convolution layers as in the downsampling block followed by a transmission up layer consists of a transposed convolutional layer (upsampling). 
The purpose of upsampling is to retrieve the dimensions and increase the resolution.
Transposed convolutional layer differs from the regular upsampling function, by introducing learnable parameters regarding the transposed convolution filters that enhance the learning process of the model. 
Moreover, after each upsampling operation, the number of feature maps used by convolutional layer reduced by half to keep the model symmetrical. 
Further, skip connections were added by appending feature maps of the downsampling block with the corresponding upsampling block to retrieve lost spatial information during the downsampling due to the reduction of the input resolution.
Therefore, the model ensures that the feature maps which were learned during the downsampling will be utilized in the reconstruction. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure} [h!]
	\begin{center}
		\includegraphics[scale= 0.8]{Unet_model.png}
	\end{center}
	\caption{U-Net architecture.} 
	\label{fig:Unet}
\end{figure}
Fig.~\ref{fig:Unet}  illustrates the network architecture. 
The encoder is on the left side in which the downsampling is performed and the decoder is on the right side where the upsampling is performed in addition to the bottleneck where is join both sides.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{VGG16 encoder-decoder}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this model, we address the use of VGG16 architecture  ~\cite{simonyan2014very} as a backbone encoder to the U-Net architecture.
VGG16 is composed of 13 convolutional layers, pooling layers and dense layers, and it is used for classification purposes. 
We applied VGG16 encoder-decoder for pixel-wise image segmentation.
Figure~\ref{vgg16} presents the architecture of VGG16 encoder-decoder model. 
The model consists of two parts: downsampling and upsampling.
The downsampling path consists of \(5\) convolutional blocks,  with a total \(13\) convolutional layers  with \enquote{same} padding with a kernel size (\(3\times3\))and 32 filters for each layer, followed by BN and activation function Relu.
Each convolutional layer is responsible for extracting high level features from the input image such as edges.
A Maxpool operation with pool size of (\(2\times2\))  and (\(2\times2\)) strides followed by dropout is performed after each convolutional block. 
The upsampling path is introduced to recover spatial resolution, it also has \(5\) convolutional blocks with a total \(13\) convolutional layers  with same padding and kernel size (\(3\times3\))and 32 filters for each layer, followed by BN and activation function Relu.
For upsampling, bilinear interpolation with (\(2\times2\)) kernel size is applied.
Skip connections were added between downsampling blocks and the corresponding upsampling blocks in order to enhance recovering fine-grained details by enabling feature re-usability from earlier layers.
\begin{figure} [h!]
	\begin{center}
		\includegraphics[scale=1]{VGG16_encoder_decoder.png}
	\end{center}
	\caption{VGG16 encoder decoder architecture.} 
	\label{vgg16}
\end{figure}
\input{fcn_densenet_model}

