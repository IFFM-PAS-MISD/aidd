\subsubsection{Pyramid Scene Parsing Network}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Pyramid Scene Parsing Network (PSPNet) was proposed by Zhao et al.~\cite{zhao2017pyramid} .
It is one of the most advanced semantic segmentation techniques. 
The principle idea of PSPNet is to provide adequate global contextual information for pixel-level scene parsing through concatenating the local and global features together. 
Hence, a spatial pyramid pooling module was introduced to perform four different pooling levels with four different pooling sizes and strides.
In this way, the pyramid pooling module is able to capture contextual features from different scales.

In this work, we implemented PSPNet with ResNet-50~\cite{He2016} as a backbone for feature map extraction with dilation at the last two layers of ResNet. 
Figure~\ref{fig:PSPNet} illustrates the implemented PSPNet architecture.
The pyramid pooling module was applied on four levels.
Global average pooling was used to produce the coarsest level of a single bin output shown in the red box. 
The other three sub-region levels have different pooling sizes of \((2\times 2), (4\times 4)\) and \((8\times8)\).
A \(1 \times 1\) convolutional layer was applied to the produced feature maps to reduce their dimensions, followed by a BN and Relu.
Then, the feature maps produced from the different levels were upsampled with bilinear interpolation.
Moreover, the upsampled features are concatenated with the output of the ResNet-50 model to obtain both local and global context information. 
Next, 2 convolutional layers were used for generating the pixel-wise segmented predictions. 
\begin{figure} [h!]
	\centering
	\includegraphics[scale=1.0]{pspsnet.png}
	\caption{PSPNet architecture.} 
	\label{fig:PSPNet}
\end{figure} 
